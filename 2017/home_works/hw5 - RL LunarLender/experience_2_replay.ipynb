{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple q-learning agent with experience replay\n",
    "\n",
    "We re-write q-learning algorithm using _agentnet_ - a helper for lasagne that implements some RL techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ! sudo pip install --upgrade https://github.com/yandexdataschool/AgentNet/archive/master.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: THEANO_FLAGS='floatX=float32'\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "%env THEANO_FLAGS='floatX=float32'\n",
    "\n",
    "#XVFB will be launched if you run on a server\n",
    "# import os\n",
    "# if type(os.environ.get(\"DISPLAY\")) is not str or len(os.environ.get(\"DISPLAY\"))==0:\n",
    "#     !bash ../xvfb start\n",
    "#     %env DISPLAY=:1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment setup\n",
    "* Here we simply load the game and check that it works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gym.envs.registration:Making new env: LunarLander-v2\n",
      "[2017-11-04 19:20:38,677] Making new env: LunarLander-v2\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "make_env = lambda: gym.make(\"LunarLander-v2\")\n",
    "\n",
    "env=make_env()\n",
    "env.reset()\n",
    "\n",
    "state_shape = env.observation_space.shape\n",
    "n_actions = env.action_space.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plt.imshow(env.render(\"rgb_array\"))\n",
    "# del env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import lasagne\n",
    "from lasagne.layers import *\n",
    "from lasagne.nonlinearities import elu\n",
    "\n",
    "\n",
    "#image observation at current tick goes here, shape = (sample_i,x,y,color)\n",
    "observation_layer = InputLayer((None,)+state_shape)\n",
    "\n",
    "\n",
    "nn = DenseLayer(observation_layer, 200, nonlinearity=elu)\n",
    "nn = DenseLayer(nn, 200, nonlinearity=elu)\n",
    "\n",
    "#a layer that predicts Qvalues\n",
    "qvalues_layer = DenseLayer(nn,num_units=n_actions,\n",
    "                           nonlinearity=None,name=\"q-values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Picking actions is done by yet another layer, that implements $ \\epsilon$ -greedy policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from agentnet.resolver import EpsilonGreedyResolver\n",
    "action_layer = EpsilonGreedyResolver(qvalues_layer)\n",
    "\n",
    "#set starting epsilon\n",
    "action_layer.epsilon.set_value(np.float32(0.05))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agent\n",
    "\n",
    "We define an agent entirely composed of a lasagne network:\n",
    "* Observations as InputLayer(s)\n",
    "* Actions as intermediate Layer(s)\n",
    "* `policy_estimators` is \"whatever else you want to keep track of\"\n",
    "\n",
    "Each parameter can be either one layer or a list of layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from agentnet.agent import Agent\n",
    "agent = Agent(observation_layers=observation_layer,\n",
    "              action_layers=action_layer,\n",
    "              policy_estimators=qvalues_layer,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[W, b, W, b, q-values.W, q-values.b]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Since it's a single lasagne network, one can get it's weights, output, etc\n",
    "weights = lasagne.layers.get_all_params(action_layer,trainable=True)\n",
    "weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create and manage a pool of atari sessions to play with\n",
    "\n",
    "* To make training more stable, we shall have an entire batch of game sessions each happening independent of others\n",
    "* Why several parallel agents help training: http://arxiv.org/pdf/1602.01783v1.pdf\n",
    "* Alternative approach: store more sessions: https://www.cs.toronto.edu/~vmnih/docs/dqn.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gym.envs.registration:Making new env: LunarLander-v2\n",
      "[2017-11-04 19:20:44,139] Making new env: LunarLander-v2\n"
     ]
    }
   ],
   "source": [
    "from agentnet.experiments.openai_gym.pool import EnvPool\n",
    "pool = EnvPool(agent,make_env,n_games=1,max_size=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actions: [[3 3 3 3 0]]\n",
      "rewards: [[ 1.19398709  1.33668181  0.2964183  -0.4319901   0.        ]]\n",
      "CPU times: user 13.5 ms, sys: 3.42 ms, total: 16.9 ms\n",
      "Wall time: 35.8 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#interact for 7 ticks\n",
    "obs_log,action_log,reward_log,_,_,_  = pool.interact(5)\n",
    "\n",
    "\n",
    "print('actions:',action_log)\n",
    "print('rewards:',reward_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#we'll train on rollouts of 10 steps (required by n-step algorithms and rnns later)\n",
    "SEQ_LENGTH=10\n",
    "\n",
    "#load first sessions (this function calls interact and stores sessions in the pool)\n",
    "\n",
    "for _ in range(100):\n",
    "    pool.update(SEQ_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# q-learning\n",
    "\n",
    "We shall now define a function that replays recent game sessions and updates network weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get agent's Qvalues obtained via experience replay\n",
    "replay = pool.experience_replay.sample_session_batch(100)\n",
    "qvalues_seq = agent.get_sessions(\n",
    "    replay,\n",
    "    session_length=SEQ_LENGTH,\n",
    "    experience_replay=True,\n",
    ")[-1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#loss for Qlearning = (Q(s,a) - (r+gamma*Q(s',a_max)))^2, like you implemented before in lasagne.\n",
    "\n",
    "from agentnet.learning import qlearning\n",
    "elwise_mse_loss = qlearning.get_elementwise_objective(qvalues_seq,\n",
    "                                                      replay.actions[0],\n",
    "                                                      replay.rewards,\n",
    "                                                      replay.is_alive,\n",
    "                                                      gamma_or_gammas=0.8,\n",
    "                                                      n_steps=1,)\n",
    "\n",
    "#compute mean loss over \"alive\" fragments\n",
    "loss = elwise_mse_loss.sum() / replay.is_alive.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get weight updates\n",
    "updates = lasagne.updates.adam(loss,weights,learning_rate=1e-4)\n",
    "\n",
    "#compile train function\n",
    "import theano\n",
    "train_step = theano.function([],loss,updates=updates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo run\n",
    "\n",
    "Play full session with an untrained agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#for MountainCar-v0 evaluation session is cropped to 200 ticks\n",
    "# untrained_reward = pool.evaluate(save_path=\"./records\",record_video=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#show video\n",
    "from IPython.display import HTML\n",
    "import os\n",
    "\n",
    "video_names = list(filter(lambda s:s.endswith(\".mp4\"),os.listdir(\"./records/\")))\n",
    "\n",
    "HTML(\"\"\"\n",
    "<video width=\"640\" height=\"480\" controls>\n",
    "  <source src=\"{}\" type=\"video/mp4\">\n",
    "</video>\n",
    "\"\"\".format(\"./records/\"+video_names[-1])) #this may or may not be _last_ video. Try other indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epoch_counter = 1 #starting epoch\n",
    "rewards = {} #full game rewards\n",
    "target_score = +20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/10000 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|          | 1/10000 [00:00<34:31,  4.83it/s]\u001b[A\n",
      "  0%|          | 2/10000 [00:00<33:04,  5.04it/s]\u001b[A\n",
      "  0%|          | 3/10000 [00:00<35:06,  4.75it/s]\u001b[A\n",
      "  1%|          | 99/10000 [00:18<24:02,  6.86it/s]INFO:gym.envs.registration:Making new env: LunarLander-v2\n",
      "[2017-11-04 19:28:56,106] Making new env: LunarLander-v2\n",
      "INFO:gym.wrappers.monitoring:Clearing 2 monitor files from previous run (because force=True was provided)\n",
      "[2017-11-04 19:28:56,118] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 125 timesteps with reward=-88.70662066621567\n",
      "Episode finished after 78 timesteps with reward=-313.2788494881552\n",
      "Episode finished after 104 timesteps with reward=-392.7823684841747"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gym.wrappers.monitoring:Finished writing results. You can upload them to the scoreboard via gym.upload('/Users/alex/Desktop/7sem/ML-mipt/ML_MIPT_2017_2/HW/HW5(RL)/records')\n",
      "[2017-11-04 19:28:56,379] Finished writing results. You can upload them to the scoreboard via gym.upload('/Users/alex/Desktop/7sem/ML-mipt/ML_MIPT_2017_2/HW/HW5(RL)/records')\n",
      "  2%|▏         | 199/10000 [00:31<22:16,  7.33it/s]INFO:gym.envs.registration:Making new env: LunarLander-v2\n",
      "[2017-11-04 19:29:09,083] Making new env: LunarLander-v2\n",
      "INFO:gym.wrappers.monitoring:Clearing 2 monitor files from previous run (because force=True was provided)\n",
      "[2017-11-04 19:29:09,094] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "iter=100\tepsilon=0.910\n",
      "Current score(mean over 3) = -264.923\n",
      "Episode finished after 133 timesteps with reward=-145.98087255748004\n",
      "Episode finished after 120 timesteps with reward=-195.6009898015193\n",
      "Episode finished after 109 timesteps with reward=-103.76521889922466"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gym.wrappers.monitoring:Finished writing results. You can upload them to the scoreboard via gym.upload('/Users/alex/Desktop/7sem/ML-mipt/ML_MIPT_2017_2/HW/HW5(RL)/records')\n",
      "[2017-11-04 19:29:09,483] Finished writing results. You can upload them to the scoreboard via gym.upload('/Users/alex/Desktop/7sem/ML-mipt/ML_MIPT_2017_2/HW/HW5(RL)/records')\n",
      "  3%|▎         | 299/10000 [00:46<20:06,  8.04it/s]INFO:gym.envs.registration:Making new env: LunarLander-v2\n",
      "[2017-11-04 19:29:24,210] Making new env: LunarLander-v2\n",
      "INFO:gym.wrappers.monitoring:Clearing 2 monitor files from previous run (because force=True was provided)\n",
      "[2017-11-04 19:29:24,223] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "iter=200\tepsilon=0.828\n",
      "Current score(mean over 3) = -148.449\n",
      "Episode finished after 142 timesteps with reward=-301.18721795035447\n",
      "Episode finished after 151 timesteps with reward=-221.85428846370638\n",
      "Episode finished after 105 timesteps with reward=-400.8184015623403"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gym.wrappers.monitoring:Finished writing results. You can upload them to the scoreboard via gym.upload('/Users/alex/Desktop/7sem/ML-mipt/ML_MIPT_2017_2/HW/HW5(RL)/records')\n",
      "[2017-11-04 19:29:24,865] Finished writing results. You can upload them to the scoreboard via gym.upload('/Users/alex/Desktop/7sem/ML-mipt/ML_MIPT_2017_2/HW/HW5(RL)/records')\n",
      "  4%|▍         | 399/10000 [01:02<23:07,  6.92it/s]INFO:gym.envs.registration:Making new env: LunarLander-v2\n",
      "[2017-11-04 19:29:40,719] Making new env: LunarLander-v2\n",
      "INFO:gym.wrappers.monitoring:Clearing 2 monitor files from previous run (because force=True was provided)\n",
      "[2017-11-04 19:29:40,730] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "iter=300\tepsilon=0.754\n",
      "Current score(mean over 3) = -307.953\n",
      "Episode finished after 180 timesteps with reward=-282.23212073592265\n",
      "Episode finished after 90 timesteps with reward=-130.1031978763137\n",
      "Episode finished after 115 timesteps with reward=-213.74051675815355"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gym.wrappers.monitoring:Finished writing results. You can upload them to the scoreboard via gym.upload('/Users/alex/Desktop/7sem/ML-mipt/ML_MIPT_2017_2/HW/HW5(RL)/records')\n",
      "[2017-11-04 19:29:41,019] Finished writing results. You can upload them to the scoreboard via gym.upload('/Users/alex/Desktop/7sem/ML-mipt/ML_MIPT_2017_2/HW/HW5(RL)/records')\n",
      "  5%|▍         | 499/10000 [01:14<16:55,  9.36it/s]INFO:gym.envs.registration:Making new env: LunarLander-v2\n",
      "[2017-11-04 19:29:52,007] Making new env: LunarLander-v2\n",
      "INFO:gym.wrappers.monitoring:Clearing 2 monitor files from previous run (because force=True was provided)\n",
      "[2017-11-04 19:29:52,020] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "iter=400\tepsilon=0.687\n",
      "Current score(mean over 3) = -208.692\n",
      "Episode finished after 124 timesteps with reward=-277.0181560674348\n",
      "Episode finished after 72 timesteps with reward=-98.98792596289321\n",
      "Episode finished after 103 timesteps with reward=-197.76229199671712"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gym.wrappers.monitoring:Finished writing results. You can upload them to the scoreboard via gym.upload('/Users/alex/Desktop/7sem/ML-mipt/ML_MIPT_2017_2/HW/HW5(RL)/records')\n",
      "[2017-11-04 19:29:52,212] Finished writing results. You can upload them to the scoreboard via gym.upload('/Users/alex/Desktop/7sem/ML-mipt/ML_MIPT_2017_2/HW/HW5(RL)/records')\n",
      "  6%|▌         | 599/10000 [01:31<20:25,  7.67it/s]INFO:gym.envs.registration:Making new env: LunarLander-v2\n",
      "[2017-11-04 19:30:09,649] Making new env: LunarLander-v2\n",
      "INFO:gym.wrappers.monitoring:Clearing 2 monitor files from previous run (because force=True was provided)\n",
      "[2017-11-04 19:30:09,678] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "iter=500\tepsilon=0.626\n",
      "Current score(mean over 3) = -191.256\n",
      "Episode finished after 174 timesteps with reward=-183.05261959854747\n",
      "Episode finished after 101 timesteps with reward=-109.91371435105816\n",
      "Episode finished after 300 timesteps with reward=-361.80096253589545"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gym.wrappers.monitoring:Finished writing results. You can upload them to the scoreboard via gym.upload('/Users/alex/Desktop/7sem/ML-mipt/ML_MIPT_2017_2/HW/HW5(RL)/records')\n",
      "[2017-11-04 19:30:11,367] Finished writing results. You can upload them to the scoreboard via gym.upload('/Users/alex/Desktop/7sem/ML-mipt/ML_MIPT_2017_2/HW/HW5(RL)/records')\n",
      "  7%|▋         | 699/10000 [01:48<16:51,  9.20it/s]INFO:gym.envs.registration:Making new env: LunarLander-v2\n",
      "[2017-11-04 19:30:26,593] Making new env: LunarLander-v2\n",
      "INFO:gym.wrappers.monitoring:Clearing 2 monitor files from previous run (because force=True was provided)\n",
      "[2017-11-04 19:30:26,604] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "iter=600\tepsilon=0.571\n",
      "Current score(mean over 3) = -218.256\n",
      "Episode finished after 209 timesteps with reward=-185.92880730350907\n",
      "Episode finished after 245 timesteps with reward=-67.57555989305652\n",
      "Episode finished after 109 timesteps with reward=-161.0608798700115"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gym.wrappers.monitoring:Finished writing results. You can upload them to the scoreboard via gym.upload('/Users/alex/Desktop/7sem/ML-mipt/ML_MIPT_2017_2/HW/HW5(RL)/records')\n",
      "[2017-11-04 19:30:27,068] Finished writing results. You can upload them to the scoreboard via gym.upload('/Users/alex/Desktop/7sem/ML-mipt/ML_MIPT_2017_2/HW/HW5(RL)/records')\n",
      "  8%|▊         | 799/10000 [02:00<16:49,  9.12it/s]INFO:gym.envs.registration:Making new env: LunarLander-v2\n",
      "[2017-11-04 19:30:38,268] Making new env: LunarLander-v2\n",
      "INFO:gym.wrappers.monitoring:Clearing 2 monitor files from previous run (because force=True was provided)\n",
      "[2017-11-04 19:30:38,279] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "iter=700\tepsilon=0.522\n",
      "Current score(mean over 3) = -138.188\n",
      "Episode finished after 288 timesteps with reward=-69.4573730336044\n",
      "Episode finished after 85 timesteps with reward=-109.33435172496496\n",
      "Episode finished after 197 timesteps with reward=-185.1964502340478"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gym.wrappers.monitoring:Finished writing results. You can upload them to the scoreboard via gym.upload('/Users/alex/Desktop/7sem/ML-mipt/ML_MIPT_2017_2/HW/HW5(RL)/records')\n",
      "[2017-11-04 19:30:38,707] Finished writing results. You can upload them to the scoreboard via gym.upload('/Users/alex/Desktop/7sem/ML-mipt/ML_MIPT_2017_2/HW/HW5(RL)/records')\n",
      "  9%|▉         | 899/10000 [02:14<21:59,  6.89it/s]INFO:gym.envs.registration:Making new env: LunarLander-v2\n",
      "[2017-11-04 19:30:51,957] Making new env: LunarLander-v2\n",
      "INFO:gym.wrappers.monitoring:Clearing 2 monitor files from previous run (because force=True was provided)\n",
      "[2017-11-04 19:30:51,973] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "iter=800\tepsilon=0.477\n",
      "Current score(mean over 3) = -121.329\n",
      "Episode finished after 213 timesteps with reward=-97.80983611197534\n",
      "Episode finished after 350 timesteps with reward=-251.5096757026163\n",
      "Episode finished after 1000 timesteps with reward=14.807460905535006"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gym.wrappers.monitoring:Finished writing results. You can upload them to the scoreboard via gym.upload('/Users/alex/Desktop/7sem/ML-mipt/ML_MIPT_2017_2/HW/HW5(RL)/records')\n",
      "[2017-11-04 19:30:55,719] Finished writing results. You can upload them to the scoreboard via gym.upload('/Users/alex/Desktop/7sem/ML-mipt/ML_MIPT_2017_2/HW/HW5(RL)/records')\n",
      " 10%|▉         | 999/10000 [02:33<24:01,  6.24it/s]INFO:gym.envs.registration:Making new env: LunarLander-v2\n",
      "[2017-11-04 19:31:11,383] Making new env: LunarLander-v2\n",
      "INFO:gym.wrappers.monitoring:Clearing 2 monitor files from previous run (because force=True was provided)\n",
      "[2017-11-04 19:31:11,400] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "iter=900\tepsilon=0.436\n",
      "Current score(mean over 3) = -111.504\n",
      "Episode finished after 128 timesteps with reward=-98.85379024063208\n",
      "Episode finished after 236 timesteps with reward=-246.63543090075916\n",
      "Episode finished after 378 timesteps with reward=-198.33634667667604"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gym.wrappers.monitoring:Finished writing results. You can upload them to the scoreboard via gym.upload('/Users/alex/Desktop/7sem/ML-mipt/ML_MIPT_2017_2/HW/HW5(RL)/records')\n",
      "[2017-11-04 19:31:12,672] Finished writing results. You can upload them to the scoreboard via gym.upload('/Users/alex/Desktop/7sem/ML-mipt/ML_MIPT_2017_2/HW/HW5(RL)/records')\n",
      " 11%|█         | 1099/10000 [02:53<21:07,  7.03it/s]INFO:gym.envs.registration:Making new env: LunarLander-v2\n",
      "[2017-11-04 19:31:30,937] Making new env: LunarLander-v2\n",
      "INFO:gym.wrappers.monitoring:Clearing 2 monitor files from previous run (because force=True was provided)\n",
      "[2017-11-04 19:31:30,949] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "iter=1000\tepsilon=0.399\n",
      "Current score(mean over 3) = -181.275\n",
      "Episode finished after 271 timesteps with reward=-172.3358117755581\n",
      "Episode finished after 308 timesteps with reward=-146.82736457574003\n",
      "Episode finished after 386 timesteps with reward=-102.12510312950316"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gym.wrappers.monitoring:Finished writing results. You can upload them to the scoreboard via gym.upload('/Users/alex/Desktop/7sem/ML-mipt/ML_MIPT_2017_2/HW/HW5(RL)/records')\n",
      "[2017-11-04 19:31:32,253] Finished writing results. You can upload them to the scoreboard via gym.upload('/Users/alex/Desktop/7sem/ML-mipt/ML_MIPT_2017_2/HW/HW5(RL)/records')\n",
      " 12%|█▏        | 1199/10000 [03:09<41:55,  3.50it/s]INFO:gym.envs.registration:Making new env: LunarLander-v2\n",
      "[2017-11-04 19:31:47,000] Making new env: LunarLander-v2\n",
      "INFO:gym.wrappers.monitoring:Clearing 2 monitor files from previous run (because force=True was provided)\n",
      "[2017-11-04 19:31:47,011] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "iter=1100\tepsilon=0.366\n",
      "Current score(mean over 3) = -140.429\n",
      "Episode finished after 591 timesteps with reward=-210.39203011545038\n",
      "Episode finished after 210 timesteps with reward=-79.30519368976731\n",
      "Episode finished after 233 timesteps with reward=-95.60271602351446"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gym.wrappers.monitoring:Finished writing results. You can upload them to the scoreboard via gym.upload('/Users/alex/Desktop/7sem/ML-mipt/ML_MIPT_2017_2/HW/HW5(RL)/records')\n",
      "[2017-11-04 19:31:50,605] Finished writing results. You can upload them to the scoreboard via gym.upload('/Users/alex/Desktop/7sem/ML-mipt/ML_MIPT_2017_2/HW/HW5(RL)/records')\n",
      " 13%|█▎        | 1299/10000 [03:29<27:40,  5.24it/s]INFO:gym.envs.registration:Making new env: LunarLander-v2\n",
      "[2017-11-04 19:32:07,432] Making new env: LunarLander-v2\n",
      "INFO:gym.wrappers.monitoring:Clearing 2 monitor files from previous run (because force=True was provided)\n",
      "[2017-11-04 19:32:07,443] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "iter=1200\tepsilon=0.336\n",
      "Current score(mean over 3) = -128.433\n",
      "Episode finished after 396 timesteps with reward=-111.60304945208864\n",
      "Episode finished after 466 timesteps with reward=-31.927833481931103\n",
      "Episode finished after 497 timesteps with reward=-123.66926349699733"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gym.wrappers.monitoring:Finished writing results. You can upload them to the scoreboard via gym.upload('/Users/alex/Desktop/7sem/ML-mipt/ML_MIPT_2017_2/HW/HW5(RL)/records')\n",
      "[2017-11-04 19:32:09,607] Finished writing results. You can upload them to the scoreboard via gym.upload('/Users/alex/Desktop/7sem/ML-mipt/ML_MIPT_2017_2/HW/HW5(RL)/records')\n",
      " 14%|█▍        | 1399/10000 [03:48<20:03,  7.15it/s]INFO:gym.envs.registration:Making new env: LunarLander-v2\n",
      "[2017-11-04 19:32:26,612] Making new env: LunarLander-v2\n",
      "INFO:gym.wrappers.monitoring:Clearing 2 monitor files from previous run (because force=True was provided)\n",
      "[2017-11-04 19:32:26,632] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "iter=1300\tepsilon=0.309\n",
      "Current score(mean over 3) = -89.067\n",
      "Episode finished after 428 timesteps with reward=-165.59845521877088\n",
      "Episode finished after 392 timesteps with reward=-152.41037320304815\n",
      "Episode finished after 330 timesteps with reward=-153.35824353429444"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gym.wrappers.monitoring:Finished writing results. You can upload them to the scoreboard via gym.upload('/Users/alex/Desktop/7sem/ML-mipt/ML_MIPT_2017_2/HW/HW5(RL)/records')\n",
      "[2017-11-04 19:32:28,521] Finished writing results. You can upload them to the scoreboard via gym.upload('/Users/alex/Desktop/7sem/ML-mipt/ML_MIPT_2017_2/HW/HW5(RL)/records')\n",
      " 15%|█▍        | 1499/10000 [04:08<26:27,  5.36it/s]INFO:gym.envs.registration:Making new env: LunarLander-v2\n",
      "[2017-11-04 19:32:45,934] Making new env: LunarLander-v2\n",
      "INFO:gym.wrappers.monitoring:Clearing 2 monitor files from previous run (because force=True was provided)\n",
      "[2017-11-04 19:32:45,948] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "iter=1400\tepsilon=0.284\n",
      "Current score(mean over 3) = -157.122\n",
      "Episode finished after 432 timesteps with reward=-85.12628838074994\n",
      "Episode finished after 318 timesteps with reward=-79.77455906102094\n",
      "Episode finished after 402 timesteps with reward=-340.2320775518556"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gym.wrappers.monitoring:Finished writing results. You can upload them to the scoreboard via gym.upload('/Users/alex/Desktop/7sem/ML-mipt/ML_MIPT_2017_2/HW/HW5(RL)/records')\n",
      "[2017-11-04 19:32:48,752] Finished writing results. You can upload them to the scoreboard via gym.upload('/Users/alex/Desktop/7sem/ML-mipt/ML_MIPT_2017_2/HW/HW5(RL)/records')\n",
      " 16%|█▌        | 1599/10000 [04:26<17:49,  7.86it/s]INFO:gym.envs.registration:Making new env: LunarLander-v2\n",
      "[2017-11-04 19:33:04,541] Making new env: LunarLander-v2\n",
      "INFO:gym.wrappers.monitoring:Clearing 2 monitor files from previous run (because force=True was provided)\n",
      "[2017-11-04 19:33:04,562] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "iter=1500\tepsilon=0.262\n",
      "Current score(mean over 3) = -168.378\n",
      "Episode finished after 267 timesteps with reward=-114.11943898172635\n",
      "Episode finished after 352 timesteps with reward=-97.33345704796452\n",
      "Episode finished after 412 timesteps with reward=-270.8146239935685"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gym.wrappers.monitoring:Finished writing results. You can upload them to the scoreboard via gym.upload('/Users/alex/Desktop/7sem/ML-mipt/ML_MIPT_2017_2/HW/HW5(RL)/records')\n",
      "[2017-11-04 19:33:05,754] Finished writing results. You can upload them to the scoreboard via gym.upload('/Users/alex/Desktop/7sem/ML-mipt/ML_MIPT_2017_2/HW/HW5(RL)/records')\n",
      " 17%|█▋        | 1699/10000 [04:43<27:57,  4.95it/s]INFO:gym.envs.registration:Making new env: LunarLander-v2\n",
      "[2017-11-04 19:33:21,772] Making new env: LunarLander-v2\n",
      "INFO:gym.wrappers.monitoring:Clearing 2 monitor files from previous run (because force=True was provided)\n",
      "[2017-11-04 19:33:21,784] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "iter=1600\tepsilon=0.242\n",
      "Current score(mean over 3) = -160.756\n",
      "Episode finished after 199 timesteps with reward=-114.74804869092337\n",
      "Episode finished after 382 timesteps with reward=-129.4529653224949\n",
      "Episode finished after 382 timesteps with reward=-232.48188231070037"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gym.wrappers.monitoring:Finished writing results. You can upload them to the scoreboard via gym.upload('/Users/alex/Desktop/7sem/ML-mipt/ML_MIPT_2017_2/HW/HW5(RL)/records')\n",
      "[2017-11-04 19:33:23,030] Finished writing results. You can upload them to the scoreboard via gym.upload('/Users/alex/Desktop/7sem/ML-mipt/ML_MIPT_2017_2/HW/HW5(RL)/records')\n",
      " 18%|█▊        | 1799/10000 [04:59<21:40,  6.30it/s]INFO:gym.envs.registration:Making new env: LunarLander-v2\n",
      "[2017-11-04 19:33:37,392] Making new env: LunarLander-v2\n",
      "INFO:gym.wrappers.monitoring:Clearing 2 monitor files from previous run (because force=True was provided)\n",
      "[2017-11-04 19:33:37,403] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "iter=1700\tepsilon=0.224\n",
      "Current score(mean over 3) = -158.894\n",
      "Episode finished after 724 timesteps with reward=-309.27747590849367\n",
      "Episode finished after 424 timesteps with reward=-184.6171526682918\n",
      "Episode finished after 315 timesteps with reward=-169.0733781873438"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gym.wrappers.monitoring:Finished writing results. You can upload them to the scoreboard via gym.upload('/Users/alex/Desktop/7sem/ML-mipt/ML_MIPT_2017_2/HW/HW5(RL)/records')\n",
      "[2017-11-04 19:33:39,634] Finished writing results. You can upload them to the scoreboard via gym.upload('/Users/alex/Desktop/7sem/ML-mipt/ML_MIPT_2017_2/HW/HW5(RL)/records')\n",
      " 19%|█▉        | 1899/10000 [05:15<15:25,  8.75it/s]INFO:gym.envs.registration:Making new env: LunarLander-v2\n",
      "[2017-11-04 19:33:52,875] Making new env: LunarLander-v2\n",
      "INFO:gym.wrappers.monitoring:Clearing 2 monitor files from previous run (because force=True was provided)\n",
      "[2017-11-04 19:33:52,887] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "iter=1800\tepsilon=0.207\n",
      "Current score(mean over 3) = -220.989\n",
      "Episode finished after 254 timesteps with reward=-14.34291003438834\n",
      "Episode finished after 252 timesteps with reward=-286.7954963712695\n",
      "Episode finished after 170 timesteps with reward=-87.11751369308104"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gym.wrappers.monitoring:Finished writing results. You can upload them to the scoreboard via gym.upload('/Users/alex/Desktop/7sem/ML-mipt/ML_MIPT_2017_2/HW/HW5(RL)/records')\n",
      "[2017-11-04 19:33:53,488] Finished writing results. You can upload them to the scoreboard via gym.upload('/Users/alex/Desktop/7sem/ML-mipt/ML_MIPT_2017_2/HW/HW5(RL)/records')\n",
      " 20%|█▉        | 1999/10000 [05:28<15:53,  8.39it/s]INFO:gym.envs.registration:Making new env: LunarLander-v2\n",
      "[2017-11-04 19:34:06,271] Making new env: LunarLander-v2\n",
      "INFO:gym.wrappers.monitoring:Clearing 2 monitor files from previous run (because force=True was provided)\n",
      "[2017-11-04 19:34:06,283] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "iter=1900\tepsilon=0.192\n",
      "Current score(mean over 3) = -129.419\n",
      "Episode finished after 221 timesteps with reward=-63.37127959354876\n",
      "Episode finished after 457 timesteps with reward=-219.97990716821758\n",
      "Episode finished after 188 timesteps with reward=-233.63707888869578"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gym.wrappers.monitoring:Finished writing results. You can upload them to the scoreboard via gym.upload('/Users/alex/Desktop/7sem/ML-mipt/ML_MIPT_2017_2/HW/HW5(RL)/records')\n",
      "[2017-11-04 19:34:07,213] Finished writing results. You can upload them to the scoreboard via gym.upload('/Users/alex/Desktop/7sem/ML-mipt/ML_MIPT_2017_2/HW/HW5(RL)/records')\n",
      " 21%|██        | 2099/10000 [05:42<15:41,  8.40it/s]INFO:gym.envs.registration:Making new env: LunarLander-v2\n",
      "[2017-11-04 19:34:20,553] Making new env: LunarLander-v2\n",
      "INFO:gym.wrappers.monitoring:Clearing 2 monitor files from previous run (because force=True was provided)\n",
      "[2017-11-04 19:34:20,563] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "iter=2000\tepsilon=0.179\n",
      "Current score(mean over 3) = -172.329\n",
      "Episode finished after 354 timesteps with reward=-196.94512133740886\n",
      "Episode finished after 347 timesteps with reward=-262.7786691280447\n",
      "Episode finished after 263 timesteps with reward=-294.1806086927298"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gym.wrappers.monitoring:Finished writing results. You can upload them to the scoreboard via gym.upload('/Users/alex/Desktop/7sem/ML-mipt/ML_MIPT_2017_2/HW/HW5(RL)/records')\n",
      "[2017-11-04 19:34:21,626] Finished writing results. You can upload them to the scoreboard via gym.upload('/Users/alex/Desktop/7sem/ML-mipt/ML_MIPT_2017_2/HW/HW5(RL)/records')\n",
      " 22%|██▏       | 2199/10000 [05:56<14:59,  8.67it/s]INFO:gym.envs.registration:Making new env: LunarLander-v2\n",
      "[2017-11-04 19:34:34,156] Making new env: LunarLander-v2\n",
      "INFO:gym.wrappers.monitoring:Clearing 2 monitor files from previous run (because force=True was provided)\n",
      "[2017-11-04 19:34:34,167] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "iter=2100\tepsilon=0.166\n",
      "Current score(mean over 3) = -251.301\n",
      "Episode finished after 310 timesteps with reward=-147.33787386872575\n",
      "Episode finished after 392 timesteps with reward=-158.90887605691213\n",
      "Episode finished after 375 timesteps with reward=-114.51723327568466"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gym.wrappers.monitoring:Finished writing results. You can upload them to the scoreboard via gym.upload('/Users/alex/Desktop/7sem/ML-mipt/ML_MIPT_2017_2/HW/HW5(RL)/records')\n",
      "[2017-11-04 19:34:35,349] Finished writing results. You can upload them to the scoreboard via gym.upload('/Users/alex/Desktop/7sem/ML-mipt/ML_MIPT_2017_2/HW/HW5(RL)/records')\n",
      " 23%|██▎       | 2299/10000 [06:10<15:35,  8.23it/s]INFO:gym.envs.registration:Making new env: LunarLander-v2\n",
      "[2017-11-04 19:34:48,442] Making new env: LunarLander-v2\n",
      "INFO:gym.wrappers.monitoring:Clearing 2 monitor files from previous run (because force=True was provided)\n",
      "[2017-11-04 19:34:48,452] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "iter=2200\tepsilon=0.155\n",
      "Current score(mean over 3) = -140.255\n",
      "Episode finished after 369 timesteps with reward=-96.17838804794025\n",
      "Episode finished after 588 timesteps with reward=81.7315957762558\n",
      "Episode finished after 255 timesteps with reward=-277.023297239469"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gym.wrappers.monitoring:Finished writing results. You can upload them to the scoreboard via gym.upload('/Users/alex/Desktop/7sem/ML-mipt/ML_MIPT_2017_2/HW/HW5(RL)/records')\n",
      "[2017-11-04 19:34:50,481] Finished writing results. You can upload them to the scoreboard via gym.upload('/Users/alex/Desktop/7sem/ML-mipt/ML_MIPT_2017_2/HW/HW5(RL)/records')\n",
      " 24%|██▍       | 2399/10000 [06:25<15:05,  8.39it/s]INFO:gym.envs.registration:Making new env: LunarLander-v2\n",
      "[2017-11-04 19:35:02,954] Making new env: LunarLander-v2\n",
      "INFO:gym.wrappers.monitoring:Clearing 2 monitor files from previous run (because force=True was provided)\n",
      "[2017-11-04 19:35:02,967] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "iter=2300\tepsilon=0.145\n",
      "Current score(mean over 3) = -97.157\n",
      "Episode finished after 383 timesteps with reward=-341.18372347812186\n",
      "Episode finished after 298 timesteps with reward=-104.3649915252671\n",
      "Episode finished after 213 timesteps with reward=-151.6924184095941"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gym.wrappers.monitoring:Finished writing results. You can upload them to the scoreboard via gym.upload('/Users/alex/Desktop/7sem/ML-mipt/ML_MIPT_2017_2/HW/HW5(RL)/records')\n",
      "[2017-11-04 19:35:04,112] Finished writing results. You can upload them to the scoreboard via gym.upload('/Users/alex/Desktop/7sem/ML-mipt/ML_MIPT_2017_2/HW/HW5(RL)/records')\n",
      " 25%|██▍       | 2499/10000 [06:39<14:12,  8.80it/s]INFO:gym.envs.registration:Making new env: LunarLander-v2\n",
      "[2017-11-04 19:35:16,949] Making new env: LunarLander-v2\n",
      "INFO:gym.wrappers.monitoring:Clearing 2 monitor files from previous run (because force=True was provided)\n",
      "[2017-11-04 19:35:16,960] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "iter=2400\tepsilon=0.136\n",
      "Current score(mean over 3) = -199.080\n",
      "Episode finished after 316 timesteps with reward=-94.69266932214411\n",
      "Episode finished after 441 timesteps with reward=-271.3604311386123\n",
      "Episode finished after 727 timesteps with reward=39.58586593053322"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gym.wrappers.monitoring:Finished writing results. You can upload them to the scoreboard via gym.upload('/Users/alex/Desktop/7sem/ML-mipt/ML_MIPT_2017_2/HW/HW5(RL)/records')\n",
      "[2017-11-04 19:35:19,320] Finished writing results. You can upload them to the scoreboard via gym.upload('/Users/alex/Desktop/7sem/ML-mipt/ML_MIPT_2017_2/HW/HW5(RL)/records')\n",
      " 26%|██▌       | 2599/10000 [06:55<16:04,  7.68it/s]INFO:gym.envs.registration:Making new env: LunarLander-v2\n",
      "[2017-11-04 19:35:33,069] Making new env: LunarLander-v2\n",
      "INFO:gym.wrappers.monitoring:Clearing 2 monitor files from previous run (because force=True was provided)\n",
      "[2017-11-04 19:35:33,080] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "iter=2500\tepsilon=0.128\n",
      "Current score(mean over 3) = -108.822\n",
      "Episode finished after 345 timesteps with reward=-238.11226155682337\n",
      "Episode finished after 274 timesteps with reward=-112.77862404572238\n",
      "Episode finished after 658 timesteps with reward=200.54126786621416"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gym.wrappers.monitoring:Finished writing results. You can upload them to the scoreboard via gym.upload('/Users/alex/Desktop/7sem/ML-mipt/ML_MIPT_2017_2/HW/HW5(RL)/records')\n",
      "[2017-11-04 19:35:35,248] Finished writing results. You can upload them to the scoreboard via gym.upload('/Users/alex/Desktop/7sem/ML-mipt/ML_MIPT_2017_2/HW/HW5(RL)/records')\n",
      " 27%|██▋       | 2699/10000 [07:11<14:02,  8.67it/s]INFO:gym.envs.registration:Making new env: LunarLander-v2\n",
      "[2017-11-04 19:35:49,214] Making new env: LunarLander-v2\n",
      "INFO:gym.wrappers.monitoring:Clearing 2 monitor files from previous run (because force=True was provided)\n",
      "[2017-11-04 19:35:49,224] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "iter=2600\tepsilon=0.121\n",
      "Current score(mean over 3) = -50.117\n",
      "Episode finished after 972 timesteps with reward=102.67321713495816\n",
      "Episode finished after 265 timesteps with reward=-263.8831524512043\n",
      "Episode finished after 897 timesteps with reward=92.97627548143174"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gym.wrappers.monitoring:Finished writing results. You can upload them to the scoreboard via gym.upload('/Users/alex/Desktop/7sem/ML-mipt/ML_MIPT_2017_2/HW/HW5(RL)/records')\n",
      "[2017-11-04 19:35:53,169] Finished writing results. You can upload them to the scoreboard via gym.upload('/Users/alex/Desktop/7sem/ML-mipt/ML_MIPT_2017_2/HW/HW5(RL)/records')\n",
      " 28%|██▊       | 2799/10000 [07:32<17:38,  6.80it/s]INFO:gym.envs.registration:Making new env: LunarLander-v2\n",
      "[2017-11-04 19:36:10,284] Making new env: LunarLander-v2\n",
      "INFO:gym.wrappers.monitoring:Clearing 2 monitor files from previous run (because force=True was provided)\n",
      "[2017-11-04 19:36:10,295] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "iter=2700\tepsilon=0.114\n",
      "Current score(mean over 3) = -22.745\n",
      "Episode finished after 579 timesteps with reward=182.51965641239653\n",
      "Episode finished after 511 timesteps with reward=-336.44424197326487\n",
      "Episode finished after 409 timesteps with reward=-260.70978602494375"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gym.wrappers.monitoring:Finished writing results. You can upload them to the scoreboard via gym.upload('/Users/alex/Desktop/7sem/ML-mipt/ML_MIPT_2017_2/HW/HW5(RL)/records')\n",
      "[2017-11-04 19:36:12,548] Finished writing results. You can upload them to the scoreboard via gym.upload('/Users/alex/Desktop/7sem/ML-mipt/ML_MIPT_2017_2/HW/HW5(RL)/records')\n",
      " 29%|██▉       | 2899/10000 [07:51<19:31,  6.06it/s]INFO:gym.envs.registration:Making new env: LunarLander-v2\n",
      "[2017-11-04 19:36:28,834] Making new env: LunarLander-v2\n",
      "INFO:gym.wrappers.monitoring:Clearing 2 monitor files from previous run (because force=True was provided)\n",
      "[2017-11-04 19:36:28,845] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "iter=2800\tepsilon=0.108\n",
      "Current score(mean over 3) = -138.211\n",
      "Episode finished after 569 timesteps with reward=-147.14737759400322\n",
      "Episode finished after 638 timesteps with reward=-176.06853568318348\n",
      "Episode finished after 866 timesteps with reward=118.43702201614285"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gym.wrappers.monitoring:Finished writing results. You can upload them to the scoreboard via gym.upload('/Users/alex/Desktop/7sem/ML-mipt/ML_MIPT_2017_2/HW/HW5(RL)/records')\n",
      "[2017-11-04 19:36:33,459] Finished writing results. You can upload them to the scoreboard via gym.upload('/Users/alex/Desktop/7sem/ML-mipt/ML_MIPT_2017_2/HW/HW5(RL)/records')\n",
      " 30%|██▉       | 2999/10000 [08:10<19:36,  5.95it/s]INFO:gym.envs.registration:Making new env: LunarLander-v2\n",
      "[2017-11-04 19:36:48,689] Making new env: LunarLander-v2\n",
      "INFO:gym.wrappers.monitoring:Clearing 2 monitor files from previous run (because force=True was provided)\n",
      "[2017-11-04 19:36:48,701] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "iter=2900\tepsilon=0.102\n",
      "Current score(mean over 3) = -68.260\n",
      "Episode finished after 490 timesteps with reward=-162.92672846450216\n",
      "Episode finished after 485 timesteps with reward=-144.58844982468705\n",
      "Episode finished after 296 timesteps with reward=-88.38321773442354"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gym.wrappers.monitoring:Finished writing results. You can upload them to the scoreboard via gym.upload('/Users/alex/Desktop/7sem/ML-mipt/ML_MIPT_2017_2/HW/HW5(RL)/records')\n",
      "[2017-11-04 19:36:50,433] Finished writing results. You can upload them to the scoreboard via gym.upload('/Users/alex/Desktop/7sem/ML-mipt/ML_MIPT_2017_2/HW/HW5(RL)/records')\n",
      " 31%|███       | 3099/10000 [08:27<19:00,  6.05it/s]INFO:gym.envs.registration:Making new env: LunarLander-v2\n",
      "[2017-11-04 19:37:05,761] Making new env: LunarLander-v2\n",
      "INFO:gym.wrappers.monitoring:Clearing 2 monitor files from previous run (because force=True was provided)\n",
      "[2017-11-04 19:37:05,772] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "iter=3000\tepsilon=0.097\n",
      "Current score(mean over 3) = -131.966\n",
      "Episode finished after 502 timesteps with reward=-141.41036075690988\n",
      "Episode finished after 853 timesteps with reward=20.502647390188244\n",
      "Episode finished after 306 timesteps with reward=-265.0096136142157"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gym.wrappers.monitoring:Finished writing results. You can upload them to the scoreboard via gym.upload('/Users/alex/Desktop/7sem/ML-mipt/ML_MIPT_2017_2/HW/HW5(RL)/records')\n",
      "[2017-11-04 19:37:08,820] Finished writing results. You can upload them to the scoreboard via gym.upload('/Users/alex/Desktop/7sem/ML-mipt/ML_MIPT_2017_2/HW/HW5(RL)/records')\n",
      " 32%|███▏      | 3199/10000 [08:46<16:33,  6.84it/s]INFO:gym.envs.registration:Making new env: LunarLander-v2\n",
      "[2017-11-04 19:37:24,197] Making new env: LunarLander-v2\n",
      "INFO:gym.wrappers.monitoring:Clearing 2 monitor files from previous run (because force=True was provided)\n",
      "[2017-11-04 19:37:24,208] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "iter=3100\tepsilon=0.093\n",
      "Current score(mean over 3) = -128.639\n",
      "Episode finished after 521 timesteps with reward=-321.24551870039323\n",
      "Episode finished after 820 timesteps with reward=130.97419023611127\n",
      "Episode finished after 405 timesteps with reward=-277.5022402768647"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gym.wrappers.monitoring:Finished writing results. You can upload them to the scoreboard via gym.upload('/Users/alex/Desktop/7sem/ML-mipt/ML_MIPT_2017_2/HW/HW5(RL)/records')\n",
      "[2017-11-04 19:37:27,786] Finished writing results. You can upload them to the scoreboard via gym.upload('/Users/alex/Desktop/7sem/ML-mipt/ML_MIPT_2017_2/HW/HW5(RL)/records')\n",
      " 33%|███▎      | 3299/10000 [09:07<14:05,  7.93it/s]INFO:gym.envs.registration:Making new env: LunarLander-v2\n",
      "[2017-11-04 19:37:45,455] Making new env: LunarLander-v2\n",
      "INFO:gym.wrappers.monitoring:Clearing 2 monitor files from previous run (because force=True was provided)\n",
      "[2017-11-04 19:37:45,467] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "iter=3200\tepsilon=0.089\n",
      "Current score(mean over 3) = -155.925\n",
      "Episode finished after 945 timesteps with reward=-479.4817682452423\n",
      "Episode finished after 660 timesteps with reward=125.85041939748227\n",
      "Episode finished after 738 timesteps with reward=-111.29974724763716"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gym.wrappers.monitoring:Finished writing results. You can upload them to the scoreboard via gym.upload('/Users/alex/Desktop/7sem/ML-mipt/ML_MIPT_2017_2/HW/HW5(RL)/records')\n",
      "[2017-11-04 19:37:51,159] Finished writing results. You can upload them to the scoreboard via gym.upload('/Users/alex/Desktop/7sem/ML-mipt/ML_MIPT_2017_2/HW/HW5(RL)/records')\n",
      " 34%|███▍      | 3399/10000 [09:31<20:49,  5.28it/s]INFO:gym.envs.registration:Making new env: LunarLander-v2\n",
      "[2017-11-04 19:38:09,150] Making new env: LunarLander-v2\n",
      "INFO:gym.wrappers.monitoring:Clearing 2 monitor files from previous run (because force=True was provided)\n",
      "[2017-11-04 19:38:09,162] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "iter=3300\tepsilon=0.085\n",
      "Current score(mean over 3) = -154.977\n",
      "Episode finished after 590 timesteps with reward=130.43961868478812\n",
      "Episode finished after 843 timesteps with reward=26.78606470493358\n",
      "Episode finished after 829 timesteps with reward=39.23272207877889"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gym.wrappers.monitoring:Finished writing results. You can upload them to the scoreboard via gym.upload('/Users/alex/Desktop/7sem/ML-mipt/ML_MIPT_2017_2/HW/HW5(RL)/records')\n",
      "[2017-11-04 19:38:13,492] Finished writing results. You can upload them to the scoreboard via gym.upload('/Users/alex/Desktop/7sem/ML-mipt/ML_MIPT_2017_2/HW/HW5(RL)/records')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "iter=3400\tepsilon=0.082\n",
      "Current score(mean over 3) = 65.486\n",
      "You win!\n"
     ]
    }
   ],
   "source": [
    "from tqdm import trange\n",
    "\n",
    "for i in trange(10000):    \n",
    "    \n",
    "    #play\n",
    "    for _ in range(5):\n",
    "        pool.update(SEQ_LENGTH,append=True)\n",
    "    \n",
    "    #train\n",
    "    train_step()\n",
    "    \n",
    "    #update epsilon\n",
    "    epsilon = 0.05 + 0.95*np.exp(-epoch_counter/1000.)\n",
    "    action_layer.epsilon.set_value(np.float32(epsilon))\n",
    "    \n",
    "    #play a few games for evaluation\n",
    "    if epoch_counter%100==0:\n",
    "        rewards[epoch_counter] = np.mean(pool.evaluate(n_games=3,record_video=False))\n",
    "        print(\"iter=%i\\tepsilon=%.3f\"%(epoch_counter,action_layer.epsilon.get_value(),))\n",
    "        print(\"Current score(mean over %i) = %.3f\"%(3,np.mean(rewards[epoch_counter])))\n",
    "    \n",
    "        if rewards[epoch_counter] >= target_score:\n",
    "            print(\"You win!\")\n",
    "            break\n",
    "\n",
    "    \n",
    "    epoch_counter  +=1\n",
    "\n",
    "    \n",
    "# Time to drink some coffee!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alex/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:3: FutureWarning: pd.ewm_mean is deprecated for ndarrays and will be removed in a future version\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1197fff60>]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAD8CAYAAABzTgP2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBs9+DwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11978f588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pandas import ewma\n",
    "iters,session_rewards=zip(*sorted(rewards.items(),key=lambda k:k[0]))\n",
    "plt.plot(iters,ewma(np.array(session_rewards),span=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gym.envs.registration:Making new env: LunarLander-v2\n",
      "[2017-11-04 19:57:26,631] Making new env: LunarLander-v2\n",
      "INFO:gym.wrappers.monitoring:Clearing 2 monitor files from previous run (because force=True was provided)\n",
      "[2017-11-04 19:57:26,643] Clearing 2 monitor files from previous run (because force=True was provided)\n",
      "INFO:gym.monitoring.video_recorder:Starting new video recorder writing to /Users/alex/Desktop/7sem/ML-mipt/ML_MIPT_2017_2/HW/HW5(RL)/records/openaigym.video.62.55921.video000000.mp4\n",
      "[2017-11-04 19:57:26,648] Starting new video recorder writing to /Users/alex/Desktop/7sem/ML-mipt/ML_MIPT_2017_2/HW/HW5(RL)/records/openaigym.video.62.55921.video000000.mp4\n"
     ]
    },
    {
     "ename": "DependencyNotInstalled",
     "evalue": "Found neither the ffmpeg nor avconv executables. On OS X, you can install ffmpeg via `brew install ffmpeg`. On most Ubuntu variants, `sudo apt-get install ffmpeg` should do it. On Ubuntu 14.04, however, you'll need to install avconv with `sudo apt-get install libav-tools`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDependencyNotInstalled\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-d6ed41ce9bc9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfinal_reward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_games\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"./records\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrecord_video\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"average reward:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfinal_reward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mvideo_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".mp4\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./records/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/alex/anaconda/lib/python3.5/site-packages/agentnet/experiments/openai_gym/pool.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, n_games, save_path, use_monitor, record_video, verbose, t_max)\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_games\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0;31m# initial observation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m             \u001b[0mobservation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m             \u001b[0;31m# initial memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m             prev_memories = [np.zeros((1,) + tuple(mem.output_shape[1:]),\n",
      "\u001b[0;32m/Users/alex/anaconda/lib/python3.5/site-packages/gym/core.py\u001b[0m in \u001b[0;36mreset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0mspace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \"\"\"\n\u001b[0;32m--> 104\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'human'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/alex/anaconda/lib/python3.5/site-packages/gym/wrappers/monitoring.py\u001b[0m in \u001b[0;36m_reset\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_before_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mobservation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_after_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobservation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/alex/anaconda/lib/python3.5/site-packages/gym/wrappers/monitoring.py\u001b[0m in \u001b[0;36m_after_reset\u001b[0;34m(self, observation)\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats_recorder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mafter_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset_video_recorder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0;31m# Bump *after* all reset activity has finished\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/alex/anaconda/lib/python3.5/site-packages/gym/wrappers/monitoring.py\u001b[0m in \u001b[0;36m_reset_video_recorder\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    217\u001b[0m             \u001b[0menabled\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_video_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m         )\n\u001b[0;32m--> 219\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvideo_recorder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcapture_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_close_video_recorder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/alex/anaconda/lib/python3.5/site-packages/gym/monitoring/video_recorder.py\u001b[0m in \u001b[0;36mcapture_frame\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    119\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_encode_ansi_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_encode_image_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/alex/anaconda/lib/python3.5/site-packages/gym/monitoring/video_recorder.py\u001b[0m in \u001b[0;36m_encode_image_frame\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_encode_image_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImageEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframes_per_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoder_version'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion_info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/alex/anaconda/lib/python3.5/site-packages/gym/monitoring/video_recorder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, output_path, frame_shape, frames_per_sec)\u001b[0m\n\u001b[1;32m    257\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'ffmpeg'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDependencyNotInstalled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\"\"Found neither the ffmpeg nor avconv executables. On OS X, you can install ffmpeg via `brew install ffmpeg`. On most Ubuntu variants, `sudo apt-get install ffmpeg` should do it. On Ubuntu 14.04, however, you'll need to install avconv with `sudo apt-get install libav-tools`.\"\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDependencyNotInstalled\u001b[0m: Found neither the ffmpeg nor avconv executables. On OS X, you can install ffmpeg via `brew install ffmpeg`. On most Ubuntu variants, `sudo apt-get install ffmpeg` should do it. On Ubuntu 14.04, however, you'll need to install avconv with `sudo apt-get install libav-tools`."
     ]
    }
   ],
   "source": [
    "final_reward = pool.evaluate(n_games=10,save_path=\"./records\",record_video=True)\n",
    "\n",
    "print(\"average reward:\",final_reward)\n",
    "\n",
    "video_names = list(filter(lambda s:s.endswith(\".mp4\"),os.listdir(\"./records/\")))\n",
    "\n",
    "for video_name in video_names:\n",
    "    HTML(\"\"\"\n",
    "    <video width=\"640\" height=\"480\" controls>\n",
    "      <source src=\"{}\" type=\"video/mp4\">\n",
    "    </video>\n",
    "    \"\"\".format(\"./records/\"+video_name)) #this may or may not be _last_ video. Try other indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
